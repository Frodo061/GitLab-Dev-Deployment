- name: Database provisioning
  hosts: localhost
  connection: local
  gather_facts: no
  roles:
    - role: gcp
      vars:
        gcp_zone: us-west1-b
        gcp_region: us-west1
        gcp_project: copper-gear-221110
        gcp_cred_kind: serviceaccount
        gcp_cred_file: .gcloud/gcloud.json
        gcp_machine_type: n1-standard-4
        source_image: projects/ubuntu-os-cloud/global/images/ubuntu-1604-xenial-v20181030
        disk_size: 12

        disks:
          # - consul-disk-01
          # - consul-disk-02
          # - consul-disk-03
          - database-disk-04
          # - database-disk-05
          # - database-disk-06
          # - pgbouncer-disk-07

        addresses:
          # - addr-1
          # - addr-2
          # - addr-3
          - addr-4
          # - addr-5
          # - addr-6
          # - addr-7

        instances:
          # - { index: 1, tag: [consul, omnibus], name: consul-1 }
          # - { index: 2, tag: [consul, omnibus], name: consul-2 }
          # - { index: 3, tag: [consul, omnibus], name: consul-3 }
          - { index: 1, tag: [database-master, omnibus, beat], name: database-master }
          # - { index: 5, tag: [database-slave, omnibus], name: database-1 }
          # - { index: 6, tag: [database-slave, omnibus], name: database-2 }
          # - { index: 7, tag: [pgbouncer, omnibus], name: pgbouncer }

        # VPC main network
        network_name: gitlab-network
        firewall_private_name: gitlab-private-firewall
        firewall_public_name: gitlab-public-firewall
        subnetwork_private_ports: [22, 80, 2049, 5432, 5601, 6379, 6432, 8301, 9200, 26379]
        subnetwork_public_ports: [22, 80, 5601, 9000]

- name: GitLab provisioning
  hosts: localhost
  connection: local
  gather_facts: no
  roles:
    - role: gcp
      vars:
        gcp_zone: us-east1-b
        gcp_region: us-east1
        gcp_project: copper-gear-221110
        gcp_cred_kind: serviceaccount
        gcp_cred_file: .gcloud/gcloud.json
        gcp_machine_type: n1-standard-4
        source_image: projects/ubuntu-os-cloud/global/images/ubuntu-1604-xenial-v20181030
        disk_size: 12
        
        disks:
          - gitlab-1-disk
          - gitlab-2-disk
        
        addresses:
          - gitlab-1-addr
          - gitlab-2-addr
        
        instances:
          - { index: 1, tag: [gitlab, omnibus, beat], name: gitlab-1 }
          - { index: 2, tag: [gitlab, omnibus, beat], name: gitlab-2 }

        # VPC main network
        network_name: gitlab-network
        firewall_private_name: gitlab-private-firewall
        firewall_public_name: gitlab-public-firewall
        subnetwork_private_ports: [22, 80, 2049, 5432, 5601, 6379, 6432, 8301, 9200, 26379]
        subnetwork_public_ports: [22, 80, 5601, 9000]

- name: GitLab provisioning
  hosts: localhost
  connection: local
  gather_facts: no
  roles:
    - role: gcp
      vars:
        gcp_zone: us-east1-b
        gcp_region: us-east1
        gcp_project: copper-gear-221110
        gcp_cred_kind: serviceaccount
        gcp_cred_file: .gcloud/gcloud.json
        gcp_machine_type: n1-standard-2
        source_image: projects/ubuntu-os-cloud/global/images/ubuntu-1604-xenial-v20181030
        disk_size: 12
        
        disks:
          - haproxy-disk
          - redis-1-disk
          - redis-2-disk
          - redis-3-disk
          - nfs-disk
          - monitor-disk
        
        addresses:
          - haproxy-addr
          - redis-1-addr
          - redis-2-addr
          - redis-3-addr
          - nfs-addr
          - monitor-addr
        
        instances:
          - { index: 1, tag: [haproxy, beat], name: haproxy }
          - { index: 2, tag: [redis, omnibus, beat], name: redis-master }
          - { index: 3, tag: [redis, omnibus, beat], name: redis-slave-1 }
          - { index: 4, tag: [redis, omnibus, beat], name: redis-slave-2 }
          - { index: 5, tag: [nfs, beat], name: nfs }
          - { index: 6, tag: [elastic], name: monitor }

        # VPC main network
        network_name: gitlab-network
        firewall_private_name: gitlab-private-firewall
        firewall_public_name: gitlab-public-firewall
        subnetwork_private_ports: [22, 80, 2049, 5432, 5601, 6379, 6432, 8301, 9200, 26379]
        subnetwork_public_ports: [22, 80, 5601, 9000]
        
- name: Debug (get all ip addrs)
  hosts: all
  gather_facts: yes
  tasks:
    - debug:
        msg: "{{ ansible_hostname }}"

- name: Export variables to .bashrc
  hosts: all
  tasks:
    - blockinfile:
        dest: "~/.bashrc"
        block: |
          export LC_CTYPE=en_US.UTF-8
          export LC_ALL=en_US.UTF-8
        insertafter: EOF
        create: yes

- name: Installing Omnibus
  hosts:
    - omnibus
  become: yes
  gather_facts: yes
  roles:
    - role: omnibus

# DATABASE
# --------------------------------------------
# - name: Installing Consul
#   hosts:
#     - consul
#   become: yes
#   gather_facts: yes
#   roles:
#     - role: consul
#       vars:
#         - consul_hosts: "{{ groups['consul'] }}"

- name: Intalling master postgres node
  hosts:
    - database-master
  become: yes
  gather_facts: yes
  roles:
    - role: postgres_master
      vars:
        listen_address: 0.0.0.0
        listen_port: 5432
        # FOR NON-HA
        sql_user: gitlab
        sql_user_password: b7a289c0600988fe8e709dd2887e4d37
        trust_auth_cidr_addresses: 10.240.0.0/16
        # FOR HA
        # trust_auth_cidr_addresses: 10.240.0.0/16
        # pgbouncer_user_password: be5544d3807b54dd0637f2439ecb03b9
        # sql_user_password: b7a289c0600988fe8e709dd2887e4d37
        # consul_hosts: "{{ groups['consul'] }}"

# - name: Intalling secondary postgres nodes
#   hosts:
#     - database-slave
#   become: yes
#   gather_facts: yes
#   roles:
#     - role: postgres_slave
#       vars:
#         listen_address: 0.0.0.0
#         trust_auth_cidr_addresses: 10.240.0.0/16
#         pgbouncer_user_password: be5544d3807b54dd0637f2439ecb03b9
#         sql_user_password: b7a289c0600988fe8e709dd2887e4d37
#         consul_hosts: "{{ groups['consul'] }}"

# - name: Intalling pgbouncer
#   hosts:
#     - pgbouncer
#   become: yes
#   gather_facts: yes
#   roles:
#     - role: pgbouncer
#       vars:
#         pgbouncer_user_password: be5544d3807b54dd0637f2439ecb03b9
#         consul_user_password: bc175b38365ec8781fa93720255dee85
#         consul_hosts: "{{ groups['consul'] }}"
#         listen_addr: "{{ ansible_default_ipv4.address }}"
#         listen_port: 6432


# GITLAB
# --------------------------------------------
- name: Installing HAproxy
  hosts:
    - haproxy
  become: yes
  gather_facts: yes
  roles:
    - role: haproxy
      vars:
        # global
        haproxy_user: haproxy
        haproxy_group: haproxy
        haproxy_global_vars:
          - maxconn 256
        # frontend
        frontend_name: 'http-frontend'
        bind_address: '*'
        # GitLab
        gitlab_frontend_port: 80
        gitlab_backend_port: 80
        gitlab_backend_name: 'http-backend-gitlab'
        gitlab_backend_balance_method: roundrobin
        gitlab_backend_servers: "{{ groups['gitlab'] }}"
        # Kibana
        kibana_frontend_port: 5601
        kibana_backend_port: 5601
        kibana_backend_name: 'http-backend-kibana'
        kibana_backend_server: "{{ hostvars[groups['elastic'][0]]['ansible_default_ipv4']['address'] }}"

- name: Installing Redis Master and Slaves
  hosts:
    - redis
  become: yes
  gather_facts: yes
  roles:
    - role: redis
      vars:
        # HOST
        redis_host_address: "{{ ansible_default_ipv4.address }}"
        redis_host_port: 6379
        redis_cluster_name: gitlab-redis
        redis_cluster_password: redis-password-goes-here
        # MASTER
        redis_master_address: "{{ hostvars[groups['redis'][0]]['ansible_default_ipv4']['address'] }}"
        redis_master_port: 6379
        # SENTINEL HOST
        sentinel_address: "{{ ansible_default_ipv4.address }}"
        sentinel_port: 26379
        sentinel_quorum: 2


- name: Installing NFS
  hosts:
    - nfs
  become: yes
  roles:
    - role: nfs
      vars:
        cidr_addresses: 10.240.0.0/16


- name: Installing GitLab
  hosts:
    - gitlab
  become: yes
  gather_facts: yes
  roles:
    - role: gitlab
      vars:
        gitlab_external_url: "{{ groups['haproxy'][0] }}" # Haproxy external address
        gitlab_nginx_listen_port: 80
        # REDIS CLUSTER
        redis_cluster_name: gitlab-redis
        redis_cluster_password: redis-password-goes-here
        # SENTINEL
        sentinel_hosts: "{{ groups['redis'] }}"
        sentinel_hosts_port: 26379
        # DATABASE (postgres)
        db_host: "{{ hostvars[groups['database-master'][0]]['ansible_default_ipv4']['address'] }}"
        db_port: 5432
        db_password: gitlab
        # DATABASE (pgbouncer)
        # db_host: "{{ hostvars[groups['pgbouncer'][0]]['ansible_default_ipv4']['address'] }}"
        # db_port: 6432
        # db_password: gitlab
        # NFS
        nfsserver: "{{ hostvars[groups['nfs'][0]]['ansible_default_ipv4']['address'] }}"
        nfspath: /gitlab-nfs
        nfsmount: /gitlab-nfs
        fstype: nfs4
        opts: auto,noatime,nofail,nolock,intr,tcp,lookupcache=positive


# MONITORING
# --------------------------------------------
- name: Installing Elasticsearch and Kibana
  hosts:
    - elastic
  become: yes
  roles:
    - role: elastic
      vars:
        # elasticsearch
        elasticsearch_instance_name: "monitor"
        elasticsearch_server_port: 9200
        elasticsearch_server_host: "0.0.0.0"
        # kibana
        kibana_server_port: 5601
        kibana_server_host: "0.0.0.0"
        kibana_elasticsearch_url: "http://localhost:9200"


- name: Installing Metricbeat
  hosts:
    - beat
  become: yes
  gather_facts: yes
  roles:
    - role: metricbeat
      vars:
        # elasticsearch
        elasticsearch_server_port: 9200
        kibana_server_port: 5601
        elasticsearch_server_host: "{{ hostvars[groups['elastic'][0]]['ansible_default_ipv4']['address'] }}"
        # dashboards
        enable_dashboards: true


- name: Installing Heartbeat
  hosts:
    - gitlab
    - haproxy
  become: yes
  gather_facts: yes
  roles:
    - role: heartbeat
      vars:
        # name
        name: "{{ ansible_hostname }}"
        # elasticsearch
        elasticsearch_server_host: "{{ hostvars[groups['elastic'][0]]['ansible_default_ipv4']['address'] }}"
        elasticsearch_server_port: 9200
        kibana_server_port: 5601
        # dashboards
        enable_dashboards: true


- name: Installing Filebeat on GitLab
  hosts:
    - gitlab
  become: yes
  gather_facts: yes
  roles:
    - role: filebeat
      vars:
        # log dir
        log_dirs: 
          - /var/log/gitlab/gitlab-rails/production.log
          # - /var/log/gitlab/gitaly/current
        # name
        name: "{{ ansible_hostname }}"
        # elasticsearch
        elasticsearch_server_host: "{{ hostvars[groups['elastic'][0]]['ansible_default_ipv4']['address'] }}"
        elasticsearch_server_port: 9200
        kibana_server_port: 5601
        # dashboards
        enable_dashboards: true


- name: Installing Filebeat on Redis
  hosts:
    - redis
  become: yes
  gather_facts: yes
  roles:
    - role: filebeat
      vars:
        # log dir
        log_dirs:
          # - /var/log/gitlab/redis/current
          - /var/log/gitlab/sentinel/current
        # name
        name: "{{ ansible_hostname }}"
        # elasticsearch
        elasticsearch_server_host: "{{ hostvars[groups['elastic'][0]]['ansible_default_ipv4']['address'] }}"
        elasticsearch_server_port: 9200
        kibana_server_port: 5601
        # dashboards
        enable_dashboards: true


- name: Installing Filebeat on Database
  hosts:
    - database-master
  become: yes
  gather_facts: yes
  roles:
    - role: filebeat
      vars:
        # log dir
        log_dirs:
          - /var/log/gitlab/postgresql/current
        # name
        name: "{{ ansible_hostname }}"
        # elasticsearch
        elasticsearch_server_host: "{{ hostvars[groups['elastic'][0]]['ansible_default_ipv4']['address'] }}"
        elasticsearch_server_port: 9200
        kibana_server_port: 5601
        # dashboards
        enable_dashboards: true
